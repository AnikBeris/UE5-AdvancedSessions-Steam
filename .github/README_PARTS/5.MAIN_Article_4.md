# Расчет предназначен для практического использования при настройке `listen server` и `dedicated server` в `Unreal Engine`. Сетевой пропускной способности игры из файла `DefaultEngine.ini`

## Параметры `GameNetworkManager` и `MaxClientRate`

постараюсь объяснять **как инженерно рассчитываются** параметры сетевой пропускной способности в Unreal Engine особенно, как эта вся чехорда связана между собой.

---

## 1. Описание параметров
## [/Script/OnlineSubsystemUtils.IpNetDriver]
### MaxClientRate
<details> 
    <summary align="center"> ⚙️ Развернуть описание </summary>

```ini
[/Script/OnlineSubsystemUtils.IpNetDriver]
MaxClientRate=500000
```

   Максимальная пропускная способность **на одного клиента**, байты в секунду.

   1. Жесткий верхний лимит, выше этих байтов не прыгнет, это аварийный стоп-кран для сервера.
   2. Сервер никогда не отправит клиенту больше этого значения.
   3. Применяется до `GameNetworkManager` тоесть пишем выше!
      - Пример:
         ```ini
         [/Script/OnlineSubsystemUtils.IpNetDriver]
         MaxClientRate=500000
         [/Script/Engine.GameNetworkManager]
         TotalNetBandwidth=2000000
         ```

### почему не нада выставлять онинаковые значения!!!
> - `MaxClientRate` — аварийный стоп-кран
> - `MaxDynamicBandwidth` — плановый, нежный, средний, как хатите называйте но это лимит

</details> 

---


## [/Script/Engine.GameNetworkManager]
### MaxDynamicBandwidth

<details> 
    <summary align="center"> ⚙️ Развернуть описание </summary>

```ini
MaxDynamicBandwidth=300000
```

- `MaxDynamicBandwidth` - это максимальный лимит пропускной способности, который сервер может **динамически** выделить одному клиенту. Даже если [`MaxClientRate`](#maxclientrate) большой, то сервер никогда не даст клиенту больше указаного значения в `MaxDynamicBandwidth`

Как определить, а сколько нада? В начале Вы должны ответить на другой вопрос `сколько байт в секунду реально нужно одному активному игроку в пике?`

Типовые значения тут берём `пиковые значения`, а не среднее. Чтобы потом не удивлятся.

| Жанр         | Средний      | Впике        |
| ------------ | ------------ | ------------ |
| Кооп / экшен | 80–150 kB/s  | 180–220 kB/s |
| Шутер        | 100–180 kB/s | 250–300 kB/s |
| RPG          | 40–80 kB/s   | 100–120 kB/s |
| Стратегия    | 20–50 kB/s   | 60–80 kB/s   |

но это ещё не всё. Дальше берём наше значение к примеру `Шутер` где `PeakClient=300000 B/s` и к нему домножаем запас `от 20% до 30%` или тоже самое но в числах `от 1.2 до 2.0`

```ini
MaxDynamicBandwidth = PeakClientUsage * (1 + запас)
Где запас = 0.25 это (25 %)
```
теперь то, что получилось подставляем в формулу
```ini
MaxDynamicBandwidth = 300000 * 1.25
```
получаем `MaxDynamicBandwidth = 375000 B/s`

Очень хорошо!
Но и это ещё не всё! Нам нужно проверить согласовоность с [`MaxClientRate`](#maxclientrate) где [`MaxClientRate`](#maxclientrate) должен быть на `20 – 100%` больше `MaxDynamicBandwidth` 

> ( Это даёт запас для packet bursts - это когда происходит резкое увеличение количества передаваемых данных за короткий промежуток времени и пиковых RPC а это относится к моменту максимальной нагрузки на систему удалённых вызовов процедур (Remote Procedure Call), когда количество запросов от клиентов к удалённым функциям достигает максимума)

| MaxClientRate | Поведение            |
| ------------- | -------------------- |
| 0%   это ×1   | риск дропа пакетов   |
| 20%  это ×1.2 | минимально безопасно |
| 50%  это ×1.5 | стабильно            |
| 100% это ×2.0 | с запасом            |

```ini
MaxClientRate = 375000 * 1.5
MaxClientRate = 562500 B/s
```

вот, что можем получить на выходе

| Параметр            | Значение      | Примечание                                  |
| ------------------- | ------------- | ------------------------------------------- |
| MaxDynamicBandwidth | 375000        | Рабочий потолок на клиента                  |
| MaxClientRate       | 450000–750000 | В зависимости от желаемого запаса, 1.2–2.0× |


и теперь остался последни рывок. Расчитать `TotalNetBandwidth`

   - Тут всё просто нам известно сколько играков играет на карте. К примеру `играет 8 чиловек`, также мы просчитали, что `MaxDynamicBandwidth = 375000` + нам нужен ещё один небольшой запас в виде `от 10% до 20%` или тоже самое но в числах `от 1.1 до 1.2` тогда:
   
   ```ini
   TotalNetBandwidth >= MaxDynamicBandwidth=375000 * 8 * 1.2 = 3600000 B/s
   ```

</details> 

---

### MinDynamicBandwidth

<details> 
    <summary align="center"> ⚙️ Развернуть описание </summary>


```ini
MinDynamicBandwidth=50000
```

Это гарантированный минимум трафика на клиента в байтах/сек. Даже если пул `TotalNetBandwidth` перегружен, сервер не отдаст клиенту меньше значения указаного в `MinDynamicBandwidth`. Если клиентов слишком много и пул `TotalNetBandwidth` не покрывает всех — UE начинает дропать лишние данные у низкоприоритетных акторов, но каждому клиенту будет хотя бы по `MinDynamicBandwidth`.

И зачем нам это нужен:
   - Предотвращает полное зависание клиента, когда высокоприоритетные игроки или события вытягивают весь пул `TotalNetBandwidth` насебя.
   - Обеспечивает минимальную стабильность соединения, даже при перегрузке.
   - Работает вместе с `MaxDynamicBandwidth` 


пример конфига для наглядности:

| Параметр            | Значение  |
| ------------------- | ----------|
| TotalNetBandwidth   | 3 600 000 |
| клиентов            | 8         |
| MaxDynamicBandwidth | 375 000   |
| MinDynamicBandwidth | 50 000    |

В этом случае если нагрузка привысит `MaxDynamicBandwidth=375 000` то каждый клиент получит хотя бы 50kB/s, а остальное распределится по [приоритету](#приоритеты) акторов.


</details>

---
---
---

### TotalNetBandwidth

<details> 
    <summary align="center"> ⚙️ Развернуть описание </summary>

```ini
TotalNetBandwidth=3600000
```

Общий бюджет пропускной способности сервера `на всех клиентов`. Тоесть взяли значение из `MaxClientRate`, `умножили` на `количество игроков` и потом умножили на запас `от 1.1 до 1.2` на выходе получили значение для `TotalNetBandwidth`. 

> Если суммарные потребности всех клиентов превышают это значение, сервер начинает урезать трафик.

Ещё раз для понимания `TotalNetBandwidth` — это общий пул. Когда суммарный исходящий трафик на всех (клиентов * `MaxDynamicBandwidth`) превышает пул (`TotalNetBandwidth`) то сервер начинает чикать ненужное. Как делает сервер а именно `GameNetworkManager`:

   1. Сначала распределяет пул (`TotalNetBandwidth`) среди клиентов по [приоритету](#приоритеты) акторов.
   2. Когда клиент получает свою долю по приоритету.
      - Сервер проверяет: не превышает ли ваше потребление число написанное в `MaxClientRate` и если оно всётаки превышает, то режет трафик до выставленых значений в `MaxClientRate`


---

### MinDynamicBandwidth

```ini
MinDynamicBandwidth=50000
```

Гарантированный минимум на клиента даже при перегрузке. [#когда-реально-вступает-mindynamicbandwidth](#когда-реально-вступает-mindynamicbandwidth) 


---

## 2. Порядок расчета пропускной способности в Unreal Engine

Сервер, а именно `GameNetworkManager` при создание сессии берет общий пул `TotalNetBandwidth` и делит его между всеми клиентами по принципу
1. Для каждого клиента гарантировано выделяет `MinDynamicBandwidth`, а потом, что осталось в пуле пытается разделить месжу всеми до максимального значения `MaxDynamicBandwidth`.

Потом в игру вступает драйвер `IpNetDriver` c его значениями `MaxClientRate`. 
1. Если потребление привышает значение `MaxDynamicBandwidth` даже при условие свободного пула `TotalNetBandwidth` но мы ещё не достигли потолка в виде `MaxClientRate` управление остаётся у `GameNetworkManager` и драйвер соединения `IpNetDriver` не вмешивается. Сервер начинает сортировать репликацию по [приоритету](#приоритеты) и отправляет только то, что влезло в `MaxDynamicBandwidth`. Лишнее что не влезло в зависимости от данных будут отправлено в следующих тиках.

## Репликация акторов
- низкоприоритетные обновления пропускаются
- они будут отправлены в следующих тиках

## Unreliable RPC
- дропаются
- не повторяются

## Reliable RPC
- остаются в очереди
- если их слишком много, могут заблокировать канал.


> Важно понимать, что это не потеря! Состояние мира не ломается, сервер продалжает слать последнии актуальные состояния. Промежуточные апдейты могут быть и скорей всего будут пропущены. Это нормальное сетевое сглаживание, а не ошибка.

---

## Сценарий 1

`Потребление > MaxDynamicBandwidth, но <= MaxClientRate`

```ini
RequiredBandwidth = 350 kB/s
MaxDynamicBandwidth = 250 kB/s
MaxClientRate = 500 kB/s
```

Что делает сервер

1. GameNetworkManager
   - видит, что клиент хочет 350 kB/s
   - но потолок = MaxDynamicBandwidth = 250 kB/s

выделяет ровно 250 kB/s

2. MinDynamicBandwidth
   - НЕ вступает
   - он нужен только если выделение падает ниже минимума

3. IpNetDriver
   - проверяет MaxClientRate
   - 250 kB/s < 500 kB/s = всё хорошо и драйвер не вмешивается

4. Итог
   - клиент получает 250 kB/s
   - лишние данные:
   - откладываются
      - понижаются в приоритете
      - могут быть пропущены (низкий NetPriority)




## Сценарий 2

`Потребление > MaxDynamicBandwidth и > MaxClientRate`

```ini
RequiredBandwidth = 600 kB/s
MaxDynamicBandwidth = 250 kB/s
MaxClientRate = 300 kB/s
```

Что делает сервер

1. GameNetworkManager
   - видит потребность в 600 kB/s
   - ограничивает до MaxDynamicBandwidth = 250 kB/s
   - MinDynamicBandwidth не нужен (250 kB/s > min)

2. IpNetDriver
   - получает 250 kB/s
   - проверяет MaxClientRate = 300 kB/s
   - 250 kB/s <= 300 kB/s = всё хорошо и драйвер не вмешивается

4. Итог
   - клиент всё равно получает 250 kB/s
   - превышение MaxClientRate не имеет значения, т.к. до него не дошли




## Сценарий 3 важный граничный случай
`MaxDynamicBandwidth > MaxClientRate`

```ini
RequiredBandwidth = 600 kB/s
MaxDynamicBandwidth = 400 kB/s
MaxClientRate = 300 kB/s
```

Что делает сервер

1. GameNetworkManager
   - видит потребность в 600 kB/s
   - ограничивает до MaxDynamicBandwidth = 400 kB/s
2. IpNetDriver 
   - режет до 300 kB/s
3. Вот здесь начинаются проблемы:
   - [дроп пакетов](#dropped-data-отброшенные-данные)
   - [Dropped Bunches](#dropped-bunches-сброшенные-сетевые-блоки-ue)
   - [рост latency](#рост-latency-рост-сетевой-задержки)




## Когда реально вступает `MinDynamicBandwidth`

`MinDynamicBandwidth` вступает ТОЛЬКО если:

```cs
(при распределение TotalNetBandwidth доля клиента) < MinDynamicBandwidth
```

Пример:

```ini
TotalNetBandwidth = 500 kB/s
MinDynamicBandwidth = 80 kB/s
Clients = 10 
```

Подсичтаем сколько приходится на клиента TotalNetBandwidth / Clients

```
500 / 10 = 50
Доля = 50 kB/s
```

доля кна клиента приходится 50 kB/s но MinDynamicBandwidth = 80 kB/s
   - сервер не может выполнить контракт
   - [saturation](#saturation-перегрузка-сетевого-канала), [dropped data](#dropped-data-отброшенные-данные)

Если:

```ini
TotalNetBandwidth = 500 kB/s
MinDynamicBandwidth = 80 kB/s
Clients = 6 
```

то

```
500 / 6 = 83.3
Доля = 83.3 kB/s
```

проверяем

```ini
Доля = 83.3 kB/s
MinDynamicBandwidth = 80 kB/s
```
то игрок получит гарантировано 80 kB/s остаток пула поделется между всеми.


# Итоговые правила

   - `MaxDynamicBandwidth` < `MaxClientRate`
   - `MinDynamicBandwidth` - гарантированое число `kB/s`
   - `MaxClientRate` - аварийный стоп
   - Режет сначала менеджер `GameNetworkManager`, потом драйвер `IpNetDriver`
   - Лучше не доходить до драйвера вообще


</details> 


---
---
---

## Проверка сети `stat net`

<details> 
    <summary align="center"> ⚙️ Развернуть описание </summary>

Команда в консоли:

```text
stat net
```

Следите за:
   - In Rate / Out Rate
   - Saturated Connections
   - Dropped RPC

---

## 8. Итог

- MaxClientRate - теоретический потолок
- MaxDynamicBandwidth - реальный потолок
- TotalNetBandwidth - сумма на всех
- MinDynamicBandwidth - гарантия минимума

</details> 






## Приоритеты обектов `NetPriority` при репликации

<details> 
    <summary align="center"> ⚙️ Развернуть описание </summary>

А теперь немного про приоритеты. У каждого реплицируемого актора есть параметор `NetPriority` по уполчанию `NetPriority = 1.0` 

   - UE использует формулу ( это очень упрощённо):

   ```
   EffectivePriority =
   NetPriority
    * TimeSinceLastUpdate
   / DistanceFactor
   ```

   Усреднёные значения приоритетов с игрулек `Conan Exiles`, `Dune: Awakening` и `Palworld`
      
   |Тип                |NetPriority|
   |------------------ |:----------|
   |PlayerCharacter    |3.0–4.0    |
   |PlayerWeapon       |2.5        |
   |AI боты, враги и.тд|1.5        |
   |Projectiles        |2.0–3.0    |
   |Loot / World props |0.5–1.0    |

   Тут мы понимаем, что низкоприоритетные акторы страдают первыми при отсичении

>     НО есть прикол, что владелец (Owner) имеет скрытый бонус где SetOwner(PlayerController)
>     получают:
>     - более частую репликацию
>     - меньше throttling
>     
>     Используйте для:
>     - оружия
>     - инвентаря
>     - UI-состояний

Если хотите, чтобы клиент `не страдал или страдал последним` то настриваем (буква "f" после значения 3.5f означает что это `float` ):

[NetUpdateFrequency](https://dev.epicgames.com/documentation/en-us/unreal-engine/property-replication-in-unreal-engine?application_version=5.2#data-drivennetworkupdatefrequency) - По умолчанию функция отключена, чтобы включить вписываем в консоль.

```sh
net.UseAdaptiveNetUpdateFrequency 1
```

[NetPriority](https://dev.epicgames.com/documentation/en-us/unreal-engine/actor-priority-in-unreal-engine) - Фактический приоритет рассчитывается с учетом базового `NetPriority`, чтобы дать больше данных тем, кто ближе к игроку ну или важнее для игры.  расстояния до зрителя и времени, прошедшего с момента последней репликации, . 

Пример: `NetPriority 2.0` получит в два раза больше обновлений, чем `NetPriority 1.0`. Тут главное соотношение, чем сами числа.  Нельзя улучшить сеть, просто подняв все приоритеты.



Присеты из разных игр:

1. PlayerCharacter:
   
   ```ini
   NetPriority = 3.5f;
   NetUpdateFrequency = 30.f;
   ```

2. Его оружие:
   
   ```ini
   NetPriority = 2.5f;
   bOnlyRelevantToOwner = true;
   ```

3. Мир:

   ```ini
   NetPriority <= 1.0f;
   NetUpdateFrequency <= 5.f;
   ```


   Что бы увидеть приоритет в действии две команды
      ```ini
      stat net
      ```

      ```ini
      net.DumpRelevantActors
      ```

   Тут нам важно увидеть:
   - кто отправляется первым
   - кто откладывается на потом
   - какие акторы дропаются


<div align="center">
  <img style="width: 70%; height: auto;" alt="priority-hero" src="./media/Tutorial/Article_4/priority-hero.png"/>
</div>

</details> 



* * * * * * * * * * * * * * * * * * 
* * * * * * * * * * * * * * * * * * 




# Терминология

<details> 
    <summary align="center"> ⚙️ Развернуть описание </summary>

Документ описывает ключевые сетевые термины Unreal Engine, которые часто встречаются
при настройке `GameNetworkManager`, `IpNetDriver` и анализе `Stat Net`.

Все термины приведены **с пояснениями в скобках**, чтобы избежать двусмысленности.

---

## Saturation (перегрузка сетевого канала)

**Что это:**  
Состояние, при котором сервер **не может отправить весь запланированный сетевой трафик**
из-за ограничения пропускной способности.

**Основные причины:**
- превышен `TotalNetBandwidth` (общий пул сервера)
- превышены плановые лимиты клиента (`MaxDynamicBandwidth`)
- слишком много реплицируемых акторов

**Что происходит в UE:**
- данные не помещаются в текущий сетевой тик
- часть репликации переносится на следующий тик
- низкоприоритетные акторы обновляются реже

**Визуальные симптомы:**
- рывки
- запаздывающие обновления
- рост задержек

---

## Dropped data (отброшенные данные)

**Что это:**  
Данные, которые **движок Unreal Engine решил не отправлять вовсе**, а не отложить.

**Причины:**
- превышен `MaxClientRate` (жёсткий лимит клиента)
- данные не влезли в сетевой тик
- слишком низкий приоритет актора или RPC

**Последствия:**
- клиент никогда не получит эти данные
- состояние будет догнано следующим обновлением

---

## Рост latency (рост сетевой задержки)

**Latency (задержка)** — это время между отправкой данных сервером и их получением клиентом.

**Рост latency означает:**
- клиент получает устаревшее состояние мира
- увеличивается разница между серверным и клиентским состоянием

**Причины:**
- данные копятся в очереди отправки
- сервер или сеть не успевают передавать трафик

**Проявления в игре:**
- дергание объектов
- резкие коррекции позиций
- визуальные телепорты

---

## Dropped Bunches (сброшенные сетевые блоки UE)

**Bunch (сетевой бандл UE)** — логическая единица данных внутри Unreal Engine:
- репликация свойств акторов
- RPC
- контрольные сообщения

**Dropped Bunches — это:**
- bunch был сформирован движком
- но **не был отправлен**
- и был **осознанно отброшен UE**

**Важно:**
- это НЕ потеря UDP-пакета
- это решение самого движка

**Последствия:**
- RPC может не дойти
- обновление состояния произойдёт позже, другим bunch

---

## Дроп пакетов (packet loss, потеря пакетов)

**Что это:**  
Физическая потеря UDP-пакета в сети, вне контроля Unreal Engine.

**Причины:**
- IP-фрагментация (слишком большой пакет)
- нестабильный интернет
- Wi-Fi, VPN, мобильные сети
- превышение MTU

**Отличие от Dropped Bunches:**

| Тип | Где происходит |
|-----------------|----------------------|
| Dropped Bunches | внутри Unreal Engine |
| Packet loss     | на уровне сети       |

---

## Связь терминов с сетевыми лимитами UE

| Симптом | Типичная причина |
| ------------------------------- | ------------------------------------------- |
| Saturation (перегрузка)         | `TotalNetBandwidth`, `MaxDynamicBandwidth`  |
| Dropped data (данные отброшены) | `MaxClientRate`, низкий приоритет           |
| Рост latency (задержка)         | очередь отправки, нехватка bandwidth        |
| Dropped Bunches                 | жёсткие лимиты отправки                     |
| Packet loss (потеря пакетов)    | `MaxPacket` слишком большой или плохая сеть |

---

## Краткие правила

- Если **UE не успевает отправлять** → saturation (перегрузка)
- Если **UE сам выкидывает данные** → dropped bunches
- Если **сеть теряет пакеты** → packet loss
- Если **данные копятся** → растёт latency

---

Документ предназначен для использования при:
- настройке listen server и dedicated server
- анализе `Stat Net`
- подборе `TotalNetBandwidth`, `MaxDynamicBandwidth`, `MaxClientRate`, `MaxPacket`


</details>



* * * * * * * * * * * * * * * * * * 
* * * * * * * * * * * * * * * * * * 



